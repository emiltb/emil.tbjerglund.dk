<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Open and Efficient Research</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Open and Efficient Research</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Emil Tveden Bjerglund</copyright>
    <lastBuildDate>Tue, 19 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/r/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Hvordan klarer de politiske partier sig på Facebook?</title>
      <link>/post/hvordan-klarer-de-politiske-partier-sig-paa-facebook/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/hvordan-klarer-de-politiske-partier-sig-paa-facebook/</guid>
      <description>&lt;p&gt;For ganske nyligt opdagede jeg, at der er lavet en &lt;a href=&#34;https://github.com/pablobarbera/Rfacebook&#34;&gt;RFacebook&lt;/a&gt; pakke til at trække data fra Facebooks Graph API. Det blev brugt til en analyse af &lt;a href=&#34;http://rforjournalists.com/2017/09/10/comparing-donald-trump-and-hillary-clintons-facebook-pages-during-the-us-presidential-election-2016/&#34;&gt;Donald Trump og Hillary Clintons kampagner under den seneste amerikanske valgkamp&lt;/a&gt;. Det kunne være interessant at se hvad vi kan sige om de danske politiske partier baseret på deres facebook-aktivitet.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hvem er mest aktive?&lt;/li&gt;
&lt;li&gt;Hvem er mest effektive i sin kommunikation?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dele af R-koden i dette indlæg er skjult for at øge læsbarheden, men den fulde kildekode er tilgængelig på &lt;a href=&#34;https://github.com/emiltb/emil.tbjerglund.dk/tree/master/content/post&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Det kræver en Access Token at få adgang til API’et. Den kan hentes &lt;a href=&#34;https://developers.facebook.com/tools/explorer/&#34;&gt;her&lt;/a&gt;. Jeg har gemt den i variablen &lt;code&gt;fb_token&lt;/code&gt;. Nedenstående kode henter derefter data fra partiernes facebook sider vha. &lt;code&gt;getPage()&lt;/code&gt; funktionen fra &lt;code&gt;RFacebook&lt;/code&gt; mellem 20. september 2016 og 19. september 2017. Data gemmes i en fil, således at vi ikke behøver gentage API-kaldet i en senere session (det tager nogle minutter at hente al data ned).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rfacebook)
library(lubridate)

start &amp;lt;- &amp;quot;2016/09/20&amp;quot;
end &amp;lt;- &amp;quot;2017/09/19&amp;quot;
common_caption &amp;lt;- paste0(&amp;quot;Data fra &amp;quot;, start, &amp;quot; til &amp;quot;, end, &amp;quot;\n@emilbp&amp;quot;)

if (!file.exists(&amp;quot;data/fbdata.Rdata&amp;quot;)) {
  data &amp;lt;- tibble(partinavne = c(&amp;quot;venstre.dk&amp;quot;, &amp;quot;socialdemokratiet&amp;quot;, &amp;quot;Konservative&amp;quot;,
    &amp;quot;danskfolkeparti&amp;quot;, &amp;quot;LiberalAlliance&amp;quot;, &amp;quot;radikalevenstre&amp;quot;, 
    &amp;quot;sfparti&amp;quot;, &amp;quot;enhedslisten&amp;quot;, &amp;quot;alternativet.dk&amp;quot;, 
    &amp;quot;nyeborgerlige&amp;quot;)) %&amp;gt;% 
    mutate(
      data = map(partinavne, getPage, 
        token = fb_token, n = 5000, since=start, until=end)
      ) %&amp;gt;% 
    mutate(data = map(data, as_tibble))
saveRDS(data, file = &amp;quot;data/fbdata.Rdata&amp;quot;)
} else {
  data &amp;lt;- readRDS(&amp;quot;data/fbdata.Rdata&amp;quot;)
}
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 2
##           partinavne                data
##                &amp;lt;chr&amp;gt;              &amp;lt;list&amp;gt;
##  1        venstre.dk &amp;lt;tibble [422 x 11]&amp;gt;
##  2 socialdemokratiet &amp;lt;tibble [321 x 11]&amp;gt;
##  3      Konservative &amp;lt;tibble [591 x 11]&amp;gt;
##  4   danskfolkeparti &amp;lt;tibble [371 x 11]&amp;gt;
##  5   LiberalAlliance &amp;lt;tibble [340 x 11]&amp;gt;
##  6   radikalevenstre &amp;lt;tibble [489 x 11]&amp;gt;
##  7           sfparti &amp;lt;tibble [571 x 11]&amp;gt;
##  8      enhedslisten &amp;lt;tibble [567 x 11]&amp;gt;
##  9   alternativet.dk &amp;lt;tibble [824 x 11]&amp;gt;
## 10     nyeborgerlige &amp;lt;tibble [223 x 11]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;På de respektive facebook-sider kan vi naturligvis også finde antallet af følgere - dem gemmer vi også lige, da vi skal bruge dem senere.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Antal følgere pr. 19. september 2017
no_followers &amp;lt;- tribble(
  ~partinavne, ~no_followers,
  &amp;quot;Venstre&amp;quot;, 68212,
  &amp;quot;Socialdemokratiet&amp;quot;, 93672,
  &amp;quot;Konservative&amp;quot;, 32615,
  &amp;quot;Dansk Folkeparti&amp;quot;, 84510,
  &amp;quot;Liberal Alliance&amp;quot;, 93861,
  &amp;quot;Radikale Venstre&amp;quot;, 36298,
  &amp;quot;SF&amp;quot;, 35261,
  &amp;quot;Enhedslisten&amp;quot;, 79713,
  &amp;quot;Alternativet&amp;quot;, 91329,
  &amp;quot;Nye Borgerlige&amp;quot;, 21553
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vores &lt;code&gt;data&lt;/code&gt; objekt indeholder partinavnene og en tabel med data for hvert parti. Lad os lige tage et kig på, hvilke informationer vi har tilgængelige.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(data$data[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;from_id&amp;quot;        &amp;quot;from_name&amp;quot;      &amp;quot;message&amp;quot;        &amp;quot;created_time&amp;quot;  
##  [5] &amp;quot;type&amp;quot;           &amp;quot;link&amp;quot;           &amp;quot;id&amp;quot;             &amp;quot;story&amp;quot;         
##  [9] &amp;quot;likes_count&amp;quot;    &amp;quot;comments_count&amp;quot; &amp;quot;shares_count&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vi har altså en del data på hvert post - hvornår den er afsendt, hvilken type post (video, tekst, billede) samt hvor mange likes, kommentarer og delinger der er. Især den sidste del er interessant for at undersøge hvor godt de forskellige partier præsterer på Facebook.&lt;/p&gt;
&lt;p&gt;Vi laver lige et par modifikationer til vores datasæt, for at gøre det nemmere at arbejde med. Vi tilføjer en kolonne med &lt;code&gt;mutate()&lt;/code&gt; der fortæller om partiet tilhører rød eller blå blok og retter partinavnene til så de står pænere i de plots vi laver senere med &lt;code&gt;case_when()&lt;/code&gt;. Så kobler vi antallet af følgere på tabellen med &lt;code&gt;left_join()&lt;/code&gt;, således at disse tal bliver nemmere at arbejde med senere og pakker alle tabellerne ud med &lt;code&gt;unnest()&lt;/code&gt;, således at det hele er samlet i en stor tabel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fbdata &amp;lt;- data %&amp;gt;% 
  mutate(blok = ifelse(partinavne %in% c(&amp;quot;venstre.dk&amp;quot;, &amp;quot;Konservative&amp;quot;,
    &amp;quot;danskfolkeparti&amp;quot;, &amp;quot;LiberalAlliance&amp;quot;, &amp;quot;nyeborgerlige&amp;quot;), &amp;quot;Blå&amp;quot;, &amp;quot;Rød&amp;quot;))  %&amp;gt;% 
  mutate(partinavne = case_when(
    partinavne == &amp;quot;venstre.dk&amp;quot; ~ &amp;quot;Venstre&amp;quot;,
    partinavne == &amp;quot;socialdemokratiet&amp;quot; ~ &amp;quot;Socialdemokratiet&amp;quot;,
    partinavne == &amp;quot;Konservative&amp;quot; ~ &amp;quot;Konservative&amp;quot;,
    partinavne == &amp;quot;danskfolkeparti&amp;quot; ~ &amp;quot;Dansk Folkeparti&amp;quot;,
    partinavne == &amp;quot;LiberalAlliance&amp;quot; ~ &amp;quot;Liberal Alliance&amp;quot;,
    partinavne == &amp;quot;radikalevenstre&amp;quot; ~ &amp;quot;Radikale Venstre&amp;quot;,
    partinavne == &amp;quot;sfparti&amp;quot; ~ &amp;quot;SF&amp;quot;,
    partinavne == &amp;quot;enhedslisten&amp;quot; ~ &amp;quot;Enhedslisten&amp;quot;,
    partinavne == &amp;quot;alternativet.dk&amp;quot; ~ &amp;quot;Alternativet&amp;quot;,
    partinavne == &amp;quot;nyeborgerlige&amp;quot; ~ &amp;quot;Nye Borgerlige&amp;quot;
  )) %&amp;gt;% 
  left_join(no_followers) %&amp;gt;% 
  unnest() %&amp;gt;% 
  mutate(created_time = as_datetime(created_time)) %&amp;gt;% 
  mutate(type = case_when(
    type == &amp;quot;link&amp;quot; ~ &amp;quot;Link&amp;quot;,
    type == &amp;quot;photo&amp;quot; ~ &amp;quot;Billede&amp;quot;,
    type == &amp;quot;video&amp;quot; ~ &amp;quot;Video&amp;quot;,
    TRUE ~ type
  )) %&amp;gt;% 
  select(
    partinavne, blok, no_followers, created_time, type, 
    Likes = &amp;quot;likes_count&amp;quot;, Delinger = &amp;quot;shares_count&amp;quot;, Kommentarer = &amp;quot;comments_count&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4,719 x 8
##   partinavne  blok no_followers        created_time    type Likes Delinger
##        &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;              &amp;lt;dttm&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1    Venstre   Blå        68212 2017-09-17 22:00:00 Billede   212       32
## 2    Venstre   Blå        68212 2017-09-17 22:00:00    Link   283       33
## 3    Venstre   Blå        68212 2017-09-16 22:00:00 Billede    78        9
## 4    Venstre   Blå        68212 2017-09-16 22:00:00 Billede   318       27
## 5    Venstre   Blå        68212 2017-09-15 22:00:00 Billede   201       16
## # ... with 4,714 more rows, and 1 more variables: Kommentarer &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;hvor-aktive-er-partierne&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hvor aktive er partierne?&lt;/h2&gt;
&lt;p&gt;Med disse data i hånden er det nu en smal sag at begynde selve analysen. Vi har i alt 4719 Facebook-opslag i vores datasæt. Lad os starte med at få et overblik. Hvilke partier er mest aktive?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fbdata %&amp;gt;% 
  group_by(partinavne) %&amp;gt;% 
  mutate(posts = n()) %&amp;gt;% 
  slice(1L) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(partinavne = forcats::fct_reorder(partinavne, posts)) %&amp;gt;% 
  ggplot(aes(partinavne, posts, fill = blok)) + 
    geom_col() +
    coord_flip() +
    scale_fill_manual(values = c(&amp;quot;steelblue&amp;quot;, &amp;quot;tomato&amp;quot;)) +
    theme(
      axis.title.y = element_blank(), 
      legend.position = &amp;quot;none&amp;quot;
      ) +
    labs(
      y = &amp;quot;Antal opslag&amp;quot;, 
      title = &amp;quot;Antal Facebook-opslag per parti&amp;quot;, 
      caption = common_caption
      )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/antal-opslag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Vi kan bryde det ned efter type af opslag, for at se om der er nogle tendenser.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/antal-opslag-type-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alternativet er altså ubetinget det mest aktive parti og lægger fleste links, billeder og videoer op. Kategorien Andet dækker over begivenheder, noter og helt almindelige statusopdateringer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hvem-far-mest-respons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hvem får mest respons?&lt;/h2&gt;
&lt;p&gt;At være meget aktiv på Facebook kræver blot nogle ihærdige SoMe-typer, men det der virkelig skaber værdi for partierne må være at folk reagerer på deres opslag - det giver synlighed og omtale. Vi kan sammenligne den gennemsnitlige respons for hvert parti i løbet af det sidste år.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fbdata %&amp;gt;% 
  mutate(month = floor_date(created_time, &amp;quot;month&amp;quot;)) %&amp;gt;% 
  group_by(partinavne, month) %&amp;gt;% 
  summarise(
    Likes = mean(Likes),
    Kommentarer = mean(Kommentarer),
    Delinger = mean(Delinger)
    ) %&amp;gt;% 
  gather(key = &amp;quot;param&amp;quot;, value = &amp;quot;value&amp;quot;, -partinavne, -month) %&amp;gt;% 
  ggplot(aes(month, value, color = partinavne)) +
    geom_line(size = 1.5, alpha = 0.75) +
    facet_wrap(~param, scales = &amp;quot;free_y&amp;quot;, ncol = 1) +
    scale_color_brewer(palette = &amp;quot;Paired&amp;quot;) +
    theme(
      legend.position = &amp;quot;bottom&amp;quot;, 
      legend.title = element_blank()
      ) +
    labs(
      x = &amp;quot;Måned&amp;quot;, 
      y = &amp;quot;Gennemsnit per opslag&amp;quot;, 
      title = &amp;quot;Engagement på Facebook&amp;quot;, 
      caption = common_caption
      ) +
    scale_x_datetime(date_breaks = &amp;quot;3 months&amp;quot;, date_minor_breaks = &amp;quot;1 month&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/gns-engagement-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Dansk Folkeparti høster altså gennemsnitligt flere likes og kommentarer på deres opslag end de andre partier. Nye Borgerlige har, især i de sidste måneder, fulgt godt med. DF og NB lå langt nede på listen over samlet antal opslag, men til gengæld reagerer deres følgere mere på det de skriver.&lt;/p&gt;
&lt;p&gt;Vi kan se på hvilke partier der i alt høster størst engagement på Facebook ved at se på summen af likes, kommentarer og delinger måned for måned.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/total-engagement-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Her ser vi at Dansk Folkeparti igen markerer sig i toppen, men Alternativets tilgang med rigtig mange opslag ser også ud til at give resultater, da deres totale antal likes tangerer Dansk Folkepartis. Enhedslisten ser også ud til at skille sig ud her, især hvis man sammenligner med SF, som laver cirka lige så mange opslag.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hvem-kommunikerer-mest-effektivt-og-far-mest-engagement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hvem kommunikerer mest effektivt og får mest engagement?&lt;/h2&gt;
&lt;p&gt;Det nemmeste regnestykke at lave i den her sammenhæng er nok at se på det totale antal likes for hvert parti i løbet af det sidste år.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_fbdata &amp;lt;- fbdata %&amp;gt;% 
  group_by(partinavne) %&amp;gt;% 
  mutate(
    sum_likes = sum(Likes)
    ) %&amp;gt;% 
  slice(1L) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(partinavne = forcats::fct_reorder(partinavne, sum_likes))

sum_fbdata %&amp;gt;% 
  ggplot(aes(no_followers, sum_likes, color = blok)) +
    #geom_text(aes(label = partinavne)) +
    geom_point() +
    ggrepel::geom_text_repel(aes(label = partinavne, color = blok), segment.color=&amp;quot;black&amp;quot;) +
    scale_color_manual(values = c(&amp;quot;steelblue&amp;quot;, &amp;quot;tomato&amp;quot;)) +
    scale_fill_manual(values = c(&amp;quot;steelblue&amp;quot;, &amp;quot;tomato&amp;quot;)) +
    theme(legend.position = &amp;quot;none&amp;quot;)+
      scale_y_continuous(limits = c(50000, 550000), labels = dot1000) +
      scale_x_continuous(limits = c(15000, 100000), labels = dot1000) +
    labs(
        y = &amp;quot;Antal likes&amp;quot;, 
        x = &amp;quot;Antal følgere&amp;quot;, 
        title = &amp;quot;Total antal likes og antal følgere for danske politiske partier&amp;quot;, 
        caption = common_caption
        )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/total-likes-folgere-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Her kan vi tydeligt se, at DF og Alternativet løber med sejren, sådan som det også fremgik af de tidligere figurer. DF har fået flere likes (531.986) end de tre regeringspartier tilsammen (410.743)!&lt;/p&gt;
&lt;p&gt;Spørgsmålet er, om det er fair at sammenligne på denne måde? Fra figurerne ovenfor ser vi hvilke partier der samlet set får mest respons. Det kunne være interessant at se på, hvilke partier der får flest likes pr. følger på deres side. Det vil give os et billede af, hvilke partier der relativt set får mest ud af sine opslag.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vi normaliserer derfor antallet af likes på hvert opslag med hensyn til antallet af følgere partiet har. Da der er ret stor udsving i dataene, så beregnes medianen og interkvartilbredden for at vise spredningen i dataene.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fbdata %&amp;gt;% 
  mutate(Likes = Likes / no_followers) %&amp;gt;% 
  group_by(partinavne) %&amp;gt;% 
  mutate(med_likes = median(Likes)) %&amp;gt;% 
  mutate(
    quart2 = quantile(Likes, 0.25), 
    quart3 = quantile(Likes, 0.75)) %&amp;gt;% 
  slice(1L) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(partinavne = forcats::fct_reorder(partinavne, med_likes)) %&amp;gt;% 
  ggplot(aes(partinavne, med_likes, color = blok)) +
    geom_segment(
      aes(y = quart2, yend = quart3, x = partinavne, xend = partinavne), 
      size = 0.7) +
    geom_point(aes(size = no_followers)) +
    coord_flip() +
    scale_color_manual(values = c(&amp;quot;steelblue&amp;quot;, &amp;quot;tomato&amp;quot;)) +
    scale_y_continuous(labels = dot1000) +
    theme(axis.title.y = element_blank()) +
    labs(
      y = &amp;quot;Likes per følger&amp;quot;, 
      size = &amp;quot;Antal følgere&amp;quot;, 
      color = &amp;quot;Blok&amp;quot;, 
      title = &amp;quot;Effektivitet af Facebook-opslag fra danske politiske partier&amp;quot;, 
      caption = common_caption
      ) +
  annotate(&amp;quot;rect&amp;quot;, 
    xmin = 1.7, xmax = 4.3, ymin = 0.0245, ymax = 0.0355, 
    fill = &amp;quot;white&amp;quot;, color = &amp;quot;grey90&amp;quot;
    ) +
  annotate(&amp;quot;segment&amp;quot;, x = 3, xend = 3, y = 0.025, yend = 0.035, color = &amp;quot;black&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 3.8, y = 0.03, label = &amp;quot;Interkvartilbredde&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 2.2, y = 0.0275, label = &amp;quot;Median&amp;quot;) +
  annotate(&amp;quot;point&amp;quot;, x = 3, y = 0.0275, size = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/opslag-effektivitet-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Med disse resultater i hånden ser vi en ny højdespringer: Nye Borgerlige høster markant flere likes på deres opslag i forhold til antal af følgere end de andre partier. Det tyder på at de enten er bedre til at formulere et budskab til deres målgruppe, eller har en mere engageret målgruppe der følger partiet meget aktivt. Jeg overvejede om Facebooks algoritme kunne spille ind her, således at partierne med mange følgere ikke får vist deres opslag til alle følgere uden at booste deres opslag, men ved første øjekast lader det ikke til at være tilfældet - der er markant forskel mellem antal likes per følger for hhv. DF og Venstre/LA, på trods af at de alle har cirka lige mange følgere. Jeg har fra disse data ikke mulighed for at tjekke om DF booster flere af deres opslag, og derfor får en større effekt, men jeg tror ikke det er tilfældet.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hvilken-type-opslag-virker-bedst&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hvilken type opslag virker bedst?&lt;/h2&gt;
&lt;p&gt;Til slut kunne man overveje om en bestemt strategi kan hjælpe partierne til at få flere interaktioner fra deres brugere? Får man flest likes, delinger og kommentarer på billeder, links eller videoer?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fbdata %&amp;gt;% 
  filter(type %in% c(&amp;quot;Billede&amp;quot;, &amp;quot;Link&amp;quot;, &amp;quot;Video&amp;quot;)) %&amp;gt;% 
  select(type, Likes, Kommentarer, Delinger) %&amp;gt;% 
  gather(key = &amp;quot;measure&amp;quot;, value = &amp;quot;count&amp;quot;, -type) %&amp;gt;% 
  group_by(type, measure) %&amp;gt;% 
  summarise(med = median(count)) %&amp;gt;%
  ungroup() %&amp;gt;% 
  ggplot(aes(type, med)) +
  geom_point() + 
  geom_segment(aes(x = type, xend = type, y = 0, yend = med)) +
  coord_flip() +
  facet_wrap(~measure, scales = &amp;quot;free_x&amp;quot;) +
  theme(axis.title.y = element_blank()) +
  labs(
      y = &amp;quot;Median af antal interaktioner&amp;quot;, 
      title = &amp;quot;Brugeres reaktioner med forskellige typer opslag&amp;quot;, 
      caption = common_caption
      )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-19-hvordan-klarer-de-politiske-partier-sig-paa-facebook_files/figure-html/opslag-typer-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Så forskellen, hvis den er der, er meget lille. Der skal graves mere ned i indholdet af de succesfulde opslag, for at blive klogere på hvad der gør forskellen partierne imellem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;konklusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Konklusion&lt;/h2&gt;
&lt;p&gt;Der er en enorm forskel på hvordan de danske politiske partier agerer på Facebook og hvor stor brugerinteraktion det resulterer i. Dansk Folkeparti og Alternativet høster markant flere Likes end de andre partier, mens Nye Borgerlige får relativt flest likes set i forhold til deres antal af følgere.&lt;/p&gt;
&lt;p&gt;Jeg håber at dette indlæg har været inspirerende læsning. At skrive den har for mig været endnu en god oplevelse med en spændende R pakke - jeg bliver gang på gang imponeret over mængden af frit tilgængelige pakker der er til alle tænkelige formål.&lt;/p&gt;
&lt;p&gt;Hvis du har kommentarer til mine metoder og lignende, så er du meget velkommen til at lægge en kommentar herunder.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Der er dog en hvis usikkerhed baseret på denne betragtning, da man godt kan like et opslag på en side man ikke følger. Desuden benyttes i udregningen det nuværende antal følgere på siderne, så der tages ikke højde for om det har ændret sig i løbet af året.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Combining R and Python for data analysis</title>
      <link>/post/combining-r-and-python-for-data-analysis/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/combining-r-and-python-for-data-analysis/</guid>
      <description>&lt;p&gt;As part of my PhD work I characterise nanomaterials using &lt;a href=&#34;https://en.wikipedia.org/wiki/Energy-dispersive_X-ray_spectroscopy&#34;&gt;Energy-dispersive X-ray spectroscopy (EDX)&lt;/a&gt; in a Scanning Transmission Electron Microscope. We do this to obtain spatial information about the chemical composition of a sample on the nanoscale. Basically, an image is obtained by raster-scanning the electron beam and recording an X-ray spectrum in each position. This effectively gives a 3-dimensional dataset, where for each pixel a full spectrum is recorded. Since different elements emit X-rays at different energies, we can essentially make images of each element in a sample by extracting that part of the spectrum.&lt;/p&gt;
&lt;p&gt;One of the best tools I have encountered for analysing such datasets is &lt;a href=&#34;http://hyperspy.org/&#34;&gt;HyperSpy&lt;/a&gt;. It is a Python library containing easy-to-use methods for interactively exploring and extracting features. As an example it is very easy to load a datafile and visualise the spectrum at each point.&lt;/p&gt;
&lt;video width=&#34;100%&#34; controls autoplay loop&gt;
&lt;source src=&#34;/img/Hyperspy.webm&#34; type=&#34;video/webm&#34;&gt; &lt;source src=&#34;/img/Hyperspy.mp4&#34; type=&#34;video/mp4&#34;&gt; Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Now, since HyperSpy is a Python library this obviously brings some headaches, when my preferred analysis tool is R. I could do the entire analysis in a &lt;a href=&#34;http://jupyter.org/&#34;&gt;Jupyter Notebook&lt;/a&gt;, and use matplotlib to generate pretty figures of the results. However, EDX data is only a small part of the data I work with, and all other data is analysed and plotted in R Markdown documents. This means, that I could quickly end up producing figures with inconsistent looks when displayed alongside other data.&lt;/p&gt;
&lt;p&gt;Fortunately it is possible to run Python code in an R Markdown document by &lt;a href=&#34;http://rmarkdown.rstudio.com/authoring_knitr_engines.html&#34;&gt;using a different language engine&lt;/a&gt;. This means that I can load HyperSpy from my Rmd file, run the Python code for the analysis, and then continue in a new code chunk containing R code. (Note that ’ should be replaced by ` below).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#39;&amp;#39;&amp;#39;{python}
#import hyperspy.api as hs
&amp;#39;&amp;#39;&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main drawback of doing it this way is that I am losing on the interactive explorative tools included in HyperSpy. For this reason my workflow has been to interactively explore and develop the Python code in a Jupyter Notebook, and then copy the final script to a Python chunk in an R Markdown document. I do this to keep the final product together and get a completely reproducible analysis in my R Markdown document.&lt;/p&gt;
&lt;div id=&#34;transferring-data-between-python-and-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transferring data between Python and R&lt;/h2&gt;
&lt;p&gt;The datafile used in this example is a Bruker composite file (.bcf) containing a 512x512 pixel image with 2048 channels in the energy spectrum. I use HyperSpy to integrate specific elemental peaks in the spectrum. This produces maps of each element in the sample. I would like to plot these in R, as I am more proficient at fine-tuning the plots to my desired look in ggplot2. It is however not possible to directly transfer data from a Python code chunk to an R code chunk, so I need to save the data to the disk and and then load it again. A specific package, &lt;a href=&#34;https://blog.rstudio.com/2016/03/29/feather/&#34;&gt;feather&lt;/a&gt;, was developed to transfer data frames between Python and R. However, since my data is just images, I find it easier to just save them as .tiff files and read these into R. I end up with the following Python script. If you are curious about analysing hyperspectral data with HyperSpy please see &lt;a href=&#34;http://hyperspy.org/hyperspy-doc/current/user_guide/index.html&#34;&gt;the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Load Hyperspy
import hyperspy.api as hs

# Define where to find the data
filename = &amp;#39;data/Co sample map.bcf&amp;#39;
folder = &amp;#39;data/&amp;#39;
sample = &amp;#39;Co&amp;#39;

# Read the raw datafile (.bcf)
s = hs.load(filename)[1]
print(s)

# The signal is low - rebin the data and then integrate the peaks
raw_result = s.rebin(new_shape=[256,256,2048]).get_lines_intensity()

# For each element save the result as an image
for j in range(len(raw_result)):
    fn = &amp;#39;&amp;#39;.join([folder, sample, &amp;#39;-&amp;#39;, raw_result[j].metadata.Sample.xray_lines[0]])
    raw_result[j].as_signal2D(image_axes=[0,1]).save(
      filename = fn, 
      extension = &amp;quot;tiff&amp;quot;, 
      overwrite = True
    )

# Save the scale of the image
file = open(&amp;#39;&amp;#39;.join([folder, sample,&amp;#39;_scale.txt&amp;#39;]), &amp;quot;w&amp;quot;)
print(s.axes_manager[&amp;quot;width&amp;quot;].scale, file=file)
file.close()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;EDSTEMSpectrum, title: EDX, dimensions: (512, 512|2048)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can examine the data folder from R, and see that the images were saved.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dir(&amp;quot;data/&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Co-C_Ka.tiff&amp;quot;      &amp;quot;Co-Ca_Ka.tiff&amp;quot;     &amp;quot;Co-Co_Ka.tiff&amp;quot;    
## [4] &amp;quot;Co-Mo_Ka.tiff&amp;quot;     &amp;quot;Co-Na_Ka.tiff&amp;quot;     &amp;quot;Co-O_Ka.tiff&amp;quot;     
## [7] &amp;quot;Co-S_Ka.tiff&amp;quot;      &amp;quot;Co sample map.bcf&amp;quot; &amp;quot;Co_scale.txt&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I put this vector of filenames into a tibble and read the corresponding scale (to be used later). The approach here might be overkill, but it makes it very easy to add more paths and load data from several files simultaneously.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

samples &amp;lt;- tibble(path = &amp;quot;data/&amp;quot;) %&amp;gt;% 
  mutate(filename = map(path, dir, pattern = &amp;quot;*.tiff&amp;quot;)) %&amp;gt;% 
  mutate(scale = map(path, dir, pattern = &amp;quot;[A-Za-z_]*scale.txt&amp;quot;)) %&amp;gt;% 
  mutate(scale = map(paste0(path,scale), read_lines) %&amp;gt;% as.double() * 1000) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reading-tiff-images-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reading tiff images in R&lt;/h2&gt;
&lt;p&gt;The generated tiff images can then be loaded using the &lt;code&gt;raster&lt;/code&gt; package as demonstrated below. I also spend quite I few lines of code extracting sample name and elements from the filenames, as well as wrangling the data into a long format, suitable for plotting. In the end I normalise the intensities within each map, since &lt;a href=&#34;https://stackoverflow.com/questions/17006251/vary-the-fill-scale-when-using-facet-wrap-and-geom-tile-together/42934670#42934670&#34;&gt;it is rather inconvenient to vary the fill scale when using &lt;code&gt;facet_wrap()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(raster)
library(stringr)
library(forcats)

maps &amp;lt;- samples %&amp;gt;%
  separate(filename, c(&amp;quot;sample&amp;quot;, &amp;quot;element&amp;quot;), &amp;quot;-&amp;quot;, remove = FALSE) %&amp;gt;% 
  mutate(element = str_extract(element,&amp;quot;^[A-Za-z_]*&amp;quot;)) %&amp;gt;% 
  separate(element, c(&amp;quot;element&amp;quot;, &amp;quot;edge&amp;quot;), &amp;quot;_&amp;quot;) %&amp;gt;% 
  mutate(img = map(paste0(path, .data$filename), raster)) %&amp;gt;%
  mutate(img = map(img, as, &amp;quot;SpatialPixelsDataFrame&amp;quot;)) %&amp;gt;%
  mutate(img = map(img, as_tibble)) %&amp;gt;%
  unnest() %&amp;gt;% 
  mutate(x = x*scale, y = y*scale) %&amp;gt;% 
  dplyr::select(-sample, -edge, -path, -filename) %&amp;gt;% 
  gather(key = &amp;quot;map&amp;quot;, value = &amp;quot;intensity&amp;quot;, -x, -y, -element) %&amp;gt;% 
  na.omit() %&amp;gt;% 
  dplyr::select(element, x, y, intensity) %&amp;gt;% 
  filter(element %in% c(&amp;quot;C&amp;quot;, &amp;quot;Co&amp;quot;, &amp;quot;Mo&amp;quot;, &amp;quot;S&amp;quot;, &amp;quot;O&amp;quot;)) %&amp;gt;%
  mutate(element = fct_relevel(element, &amp;quot;C&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;S&amp;quot;, &amp;quot;Mo&amp;quot;, &amp;quot;Co&amp;quot;)) %&amp;gt;% 
  group_by(element) %&amp;gt;% 
  mutate(intnorm = (intensity - min(intensity)) / (max(intensity) - min(intensity))) %&amp;gt;% 
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-5&#34;&gt;Table 1: &lt;/span&gt;maps tibble after wrangling&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;element&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;intensity&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;intnorm&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5256356&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.5769069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.6281782&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.6794494&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.7307207&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.7819920&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;268.5998&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.051271&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0477851&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From here it is very easy to plot the different elemental maps using ggplot2. I use the &lt;a href=&#34;https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html&#34;&gt;viridis&lt;/a&gt; color scale here for its many good qualities.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = maps, aes(x = x, y = y, fill = intnorm)) +
  geom_raster() +
  facet_wrap(~element, nrow = 1) +
  coord_equal() +
  viridis::scale_fill_viridis() +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(x = &amp;quot;x [nm]&amp;quot;, y = &amp;quot;y [nm]&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-08-04-combining-r-and-python-for-data-analysis_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;final-thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final thoughts&lt;/h2&gt;
&lt;p&gt;The goal of this post was to demonstrate, that a mixed analysis in R and Python can be kept in one place by working in R Markdown documents. An obvious alternative method would be to install &lt;a href=&#34;https://github.com/IRkernel/IRkernel&#34;&gt;an R kernel for Jupyter&lt;/a&gt; or &lt;a href=&#34;http://rpy.sourceforge.net/&#34;&gt;rpy2&lt;/a&gt;, which also makes it possible to mix R and Python in one notebook. This could be useful for avid Python users wishing to bring functionality from a powerful R package to their analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Viridis looks great, transitions smoothly between colors, reproduces nicely in greyscale and is easier to read for colorblind people.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Interactive data analysis using shinyGadgets</title>
      <link>/post/interactive-data-analysis-using-shinygadgets/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/interactive-data-analysis-using-shinygadgets/</guid>
      <description>&lt;p&gt;One of the main points I made in my last post was, that one of the barriers of adopting R as the main analysis tool is that people need accesible tools that makes it easy to do routine jobs very easy. In this post I will demonstrate how shinyGadgets can be used interactively in an analysis.&lt;/p&gt;
&lt;div id=&#34;routine-jobs-in-r-made-easy&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Routine jobs in R made easy&lt;/h1&gt;
&lt;p&gt;One of the jobs, that is often performed in the group is integrating cyclic voltammetry peaks to know the charge passed in a single sweep, since that tells us how many electroactive groups that reacted during one sweep. This is not necessarily easy, since there often is a large background current that needs to be substracted. We previously have had other tools (self-made software, Origin, etc.) but this is not necessarily easy.&lt;/p&gt;
&lt;p&gt;I developed an R-function to make an easier interface to do this. Here a dataframe is loaded with the cv data, and that can then be passed to an &lt;code&gt;area()&lt;/code&gt; function where the sweep number, integration limits and the order of the background polynomial can be specified.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(osc)
# file &amp;lt;- system.file(&amp;quot;extdata/cv/cv_example.txt&amp;quot;, package = &amp;quot;osc&amp;quot;)
# df &amp;lt;- echem_read(file)
# df &amp;lt;- area(df, sw = 1, x1 = -1.8, x2 = -1.4, p = 3)
# plot_area(df)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;using-interactive-shinygadgets-to-generate-analysis-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using interactive shinyGadgets to generate analysis code&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an RStudio Server for teaching</title>
      <link>/post/setting-up-an-rstudio-server-for-teaching/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/setting-up-an-rstudio-server-for-teaching/</guid>
      <description>&lt;p&gt;Installed ubuntu server 16.04 on an old laptop. After initial setup, login with the user created during install.&lt;/p&gt;

&lt;p&gt;For good measure, install the updates. Well that didn&amp;rsquo;t work, since Ubuntu 16.04 apparantly has problems with my network card (&lt;a href=&#34;https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1586875&#34; target=&#34;_blank&#34;&gt;https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1586875&lt;/a&gt;). I did not find a way to resolve that.&lt;/p&gt;

&lt;p&gt;Well, tried again with Ubuntu Server 17.04, which also did not help - at this point it is probably my knowledge on Linux systems that is the limiting factor. I instead installed the normal Ubuntu Desktop 17.04, and then both Wired and Wireless connections worked just fine.&lt;/p&gt;

&lt;p&gt;I then followed this guide: &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-r-on-ubuntu-14-04&#34; target=&#34;_blank&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-r-on-ubuntu-14-04&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo nano /etc/apt/sources.list&lt;/code&gt; and added the line &lt;code&gt;deb https://cran.rstudio.com/bin/linux/ubuntu zesty/&lt;/code&gt; to the bottom. Add key by &lt;code&gt;sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9&lt;/code&gt; (&lt;a href=&#34;https://cran.rstudio.com/bin/linux/ubuntu/README.html&#34; target=&#34;_blank&#34;&gt;https://cran.rstudio.com/bin/linux/ubuntu/README.html&lt;/a&gt;). Save and run &lt;code&gt;sudo apt-get update&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo apt-get install r-base&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install gdebi-core
wget https://download2.rstudio.org/rstudio-server-1.0.143-amd64.deb
sudo gdebi rstudio-server-1.0.143-amd64.deb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After that, the Rstudio server was installed and running. I could go to &lt;ip&gt;:8787 on another computer on the local network and log in with my user.&lt;/p&gt;

&lt;p&gt;As I wish to use this server for teaching, I need to make a bunch of packages, e.g. the tidyverse available for all users. So I start R on the server as a superuser by &lt;code&gt;sudo R&lt;/code&gt; and then run &lt;code&gt;install.packages(&#39;tidyverse&#39;, lib = &#39;/usr/local/lib/R/site-library/)&lt;/code&gt;. This takes a while, and the first times I did this some packages failed (rvest, httr, xml2, curl, openssl) due to missing dependencies. These were installed by&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install libxml2-dev
sudo apt-get install libcurl4-openssl-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After which the install of tidyverse progressed without errors&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo useradd -m andschmidt
sudo passwd andsmidt # Supply 123abc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To delete a user &lt;code&gt;sudo userdel andschmidt&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open Science tools for our research group</title>
      <link>/post/open-science-tools-for-our-research-group/</link>
      <pubDate>Mon, 10 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/open-science-tools-for-our-research-group/</guid>
      <description>&lt;p&gt;Currently in the &lt;a href=&#34;//surfchem.dk&#34;&gt;Organic Surface Chemistry group&lt;/a&gt;, there are large variations between our group members when it comes to the tools used for data analysis. Some people feel most comfortable in spreadsheet programs such as Origin or Excel, while others rely on a mix of Matlab, R, Python or other tools. We use a lot of different experimental techniques in our research, and therefore generate data in a lot of different formats. Different workflows of varying efficiency often makes joint projects more difficult than necessary.&lt;/p&gt;
&lt;div id=&#34;open-science&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Open Science&lt;/h2&gt;
&lt;p&gt;Recently a lot of our research activities has been oriented towards the &lt;a href=&#34;//www.spoman-os.org&#34;&gt;SPOMAN Open Science collaboration&lt;/a&gt;, and the ongoing projects are available on the &lt;a href=&#34;//osf.io/wudyt&#34;&gt;Open Science Framework (osf.io)&lt;/a&gt;. In most cases, the methods and results are thoroughly described for each project. However, since a lot of the data analysis is currently performed in spreadsheet software, the data analysis is not very transparent and reproducible. &lt;span class=&#34;citation&#34;&gt;Lowndes et al. (2017)&lt;/span&gt; discusses exactly this issue, and describes how the use of &lt;a href=&#34;//www.r-project.org&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;//github.com&#34;&gt;GitHub&lt;/a&gt; has allowed them to do better science in less time.&lt;/p&gt;
&lt;p&gt;I have been considering how to apply this thinking to our research. I am confident that it could be made more efficient and well-documented if R was adopted as a general tool for data analysis.&lt;/p&gt;
&lt;div id=&#34;clear-and-well-documented-analysis-in-r-markdown&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Clear and well-documented analysis in R Markdown&lt;/h3&gt;
&lt;p&gt;If you recieve a spreadsheet from someone, containing some data analysis it can be very hard to decipher the thinking of the original author (and to be honest, analysis done by yourself 6 monts ago might as well have been done by a complete stranger). Some of the challenges are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is no connection to the original data. How did the data come from your scientific equipment and into the spreadsheet? Was it in any way altered previously?&lt;/li&gt;
&lt;li&gt;What calculations are performed? Which cells contain data and formulas? You have to manually click around to know.&lt;/li&gt;
&lt;li&gt;There is no easy way to reproduce an analysis, without having to enter new formulas, making new assumptions etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R provides a very nice feature which can alleviate these challenges, and make an analysis easier to understand and reproduce: &lt;a href=&#34;//rmarkdown.rstudio.com&#34;&gt;R Markdown documents&lt;/a&gt;. &lt;em&gt;This post is written in R Markdown to demonstrate some of the capabilities (you can go &lt;a href=&#34;https://github.com/emiltb/emil.tbjerglund.dk/tree/master/content/post&#34;&gt;here&lt;/a&gt; to see the code)&lt;/em&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. It makes it easy to alternate between descriptive paragraphs, describing the analysis and intermediate conclusions, and then R code, where scripts are used to load, modify and plot data.&lt;/p&gt;
&lt;p&gt;We could for example provide the script for loading a dataset and directly show how a few of the variables are modified. This is demonstrated here for R’s built-in &lt;code&gt;mtcars&lt;/code&gt; dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
dataset &amp;lt;- mtcars %&amp;gt;% 
  mutate(wt = wt*0.45359,      # Convert lbs to tons
         mpg = mpg * 0.42514,  # Convert mpg to km/L
         Transmission = forcats::fct_recode(as.factor(am), 
                                            Automatic = &amp;quot;0&amp;quot;, 
                                            Manual = &amp;quot;1&amp;quot;)
    )

knitr::kable(
  head(dataset, 4), 
  caption = &amp;quot;The mtcars dataset contain data on 32 different cars. Here 4 rows are shown.&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:data-modify&#34;&gt;Table 1: &lt;/span&gt;The mtcars dataset contain data on 32 different cars. Here 4 rows are shown.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;car&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Transmission&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Mazda RX4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.927940&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.188406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Manual&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Mazda RX4 Wag&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.927940&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.304071&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Manual&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Datsun 710&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.693192&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;93&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.052329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Manual&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Hornet 4 Drive&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.097996&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;110&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.458292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Automatic&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can then plot our dataset, in a completely reproducible manner by a few lines of code. Anyone with the datafile and this script, would be able to produce this exact plot. Notice that the package &lt;code&gt;ggplot2&lt;/code&gt; is used, producing publication-ready figures right away.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset %&amp;gt;%  
  ggplot(aes(x = wt, y = mpg, color = Transmission)) +
  geom_point() +
  labs(x = &amp;quot;Weight (t)&amp;quot;, y = &amp;quot;Mileage (km/L)&amp;quot;, title = &amp;quot;Fuel economy&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/&#34;https://emil.tbjerglund.dk/&#34;  # End your URL with a `/` trailing slash.post/2017-07-07-open-science-tools-for-our-research-group_files/figure-html/data-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reuse-of-work-through-an-r-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reuse of work through an R package&lt;/h3&gt;
&lt;p&gt;Take any given &lt;a href=&#34;http://surfchem.dk/category/articles/&#34;&gt;research project&lt;/a&gt; in our group, and you will commonly find that we use X-ray Photoelectron Spectroscopy (XPS), Raman spectroscopy, Infrared spectroscopy, Ellipsommetry and various electrochemical techniques all the time. In essence, a handful of techniques produce the large majority of our data. Most of it is initially saved in proprietary formats and treated in the corresponding software, but it can all be exported as plain-text files (.csv, .txt). Wouldn’t it be nice to have a common framework to analyse and plot all data, for every project, regardless of the technique used? This is also possible in R by creating a package!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Packages are the fundamental units of reproducible R code. They include reusable R functions, the documentation that describes how to use them, and sample data. &lt;a href=&#34;//r-pkgs.had.co.nz/&#34;&gt;&lt;strong&gt;R packages&lt;/strong&gt;, &lt;em&gt;Hadley Wickham&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Initially, an R package for our group could contain functions to load the data from the above-mentioned techniques and clean it up, so that it is ready for analysis. We could then extend on this by providing often-used analyses as functions, shortcuts for making commonly used plots etc. In this way code could easily be reused among members of the group, making our science more efficient. Having such a toolbox provided along with some basic examples will also make it easier for new group members to get started with R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collaborative-todo-lists-and-dicussions-on-github&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Collaborative TODO-lists and dicussions on GitHub&lt;/h3&gt;
&lt;p&gt;When you have then made your R package, how is it then distributed among group members? To be truly efficient we need a tool that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easily allows users to download the newest version of the package when using R.&lt;/li&gt;
&lt;li&gt;Allows for cooperation from many users, such that the maintainence and debugging the code is independent of any single person.&lt;/li&gt;
&lt;li&gt;Contains version control, such that users can append their own code to the project or modify other peoples code without fear of breaking stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All this is possible, if the package is made publically available as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Git&#34;&gt;Git repository&lt;/a&gt;. As of writing this, I have created an empty R package that is available &lt;a href=&#34;https://github.com/SPOMAN/osc&#34;&gt;on GitHub&lt;/a&gt;, and the hope is that in due time it will be populated with lots of useful stuff for our group members. This solution makes the code publically available and very easy to use in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Install the package from Github using the Devtools package
install.packages(&amp;#39;devtools&amp;#39;)
devtools::install_github(&amp;#39;SPOMAN/osc&amp;#39;)

# Load the &amp;#39;osc&amp;#39; package
library(osc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Github further allows users and developers to &lt;a href=&#34;https://github.com/SPOMAN/osc/issues&#34;&gt;track &lt;em&gt;issues&lt;/em&gt;&lt;/a&gt;. This can be used as a TODO-list for the project to report bugs in the code or request missing features. This means, that even R users that mainly use the scripts, and might be unable to add new functionality themselves, has the possibility to help improve the package.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;key-steps-for-implementation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Key steps for implementation&lt;/h2&gt;
&lt;p&gt;It is clear, that there is an inital barrier to overcome, if the implementation of R as the primary analysis tool in our group is to succeed. Currently many students in our group have very limited experience in programming, but I believe that by implementing core tools in an accessible environment this can be overcome. Teaching R to new users was discussed extensively at the useR!2017 conference I attended last week. Some materials are available in the excellent talk &lt;a href=&#34;https://github.com/mine-cetinkaya-rundel/2017-07-05-teach-ds-to-new-user&#34;&gt;“Teaching data science to new useRs” by Mine Cetinkaya-Rundel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the long run I am confident that the extra workload that must be put into making a well-crafted R package will pay off, once the scientific analyses can be performed more efficient and reproducibly by every member of our research group.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Lowndes2017&#34;&gt;
&lt;p&gt;Lowndes, Julia S. Stewart, Benjamin D. Best, Courtney Scarborough, Jamie C. Afflerbach, Melanie R. Frazier, Casey C. O’Hara, Ning Jiang, and Benjamin S. Halpern. 2017. “Our path to better science in less time using open data science tools.” &lt;em&gt;Nature Ecology &amp;amp; Evolution&lt;/em&gt; 1 (6): 0160. doi:&lt;a href=&#34;https://doi.org/10.1038/s41559-017-0160&#34;&gt;10.1038/s41559-017-0160&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Fun fact: R Markdown can also be used to product PDFs, Word documents or even slideshows!&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
